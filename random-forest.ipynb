{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "![Alt text](./images/Forest3.jpg \"Random Forest Drawing\")\n",
    "* * *\n",
    "Drawing by Phil Cutler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Any tutorial on [Random Forests](https://en.wikipedia.org/wiki/Random_forest) (RF) should also include a review of decicion trees, as these are models that are ensembled together to create the Random Forest model -- or put another way, the \"trees that comprise the forest.\"  Much of the complexity and detail of the Random Forest algorithm occurs within the individual decision trees and therefore it's important to understand decision trees to understand the RF algorithm as a whole.  Therefore, before proceeding, it is recommended that you read through the accompanying [Classification and Regression Trees Tutorial](decision-trees.ipynb).\n",
    "\n",
    "\n",
    "## History\n",
    "\n",
    "The Random Forest algorithm is preceeded by the [Random Subspace Method](https://en.wikipedia.org/wiki/Random_subspace_method) (aka \"attribute bagging\"), which accounts for half of the source of randomness in a Random Forest.  The Random Subspace Method is an ensemble method that consists of several classifiers each operating in a subspace of the original feature space.  The outputs of the models are then combined, usually by a simple majority vote. Tin Kam Ho applied the random subspace method to decision trees in 1995.\n",
    "\n",
    "Leo Breiman and Adele Culter combined Breiman's bagging idea with the random subspace method to create a \"Random Forest\", a name which is trademarked by the duo.  Due to the trademark, the algorithm is sometimes called Random Decision Forests.\n",
    "\n",
    "The introduction of random forests proper was first made in a paper by Leo Breiman [2]. This paper describes a method of building a forest of uncorrelated trees using a CART like procedure, combined with randomized node optimization and bagging. In addition, this paper combines several ingredients, some previously known and some novel, which form the basis of the modern practice of random forests, in particular:\n",
    "\n",
    "- Using out-of-bag error as an estimate of the generalization error.\n",
    "- Measuring variable importance through permutation.\n",
    "\n",
    "The report also offers the first theoretical result for random forests in the form of a bound on the generalization error which depends on the strength of the trees in the forest and their correlation.\n",
    "\n",
    "Brieman's implemenation of Random Forests used his CART algorithm (1984), to construct the decision trees.  However, modern RF implemenations often use different algorithms for constructing the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest by Randomization (aka \"Extra-Trees\")\n",
    "\n",
    "In Extremely Randomized Trees (Extra-Trees) [1], randomness goes one step further in the way splits are computed. As in Random Forests, a random subset of candidate features is used, but instead of looking for the best split, thresholds (for the split) are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias.\n",
    "\n",
    "\n",
    "## Regularized Random Forest (RRF)\n",
    "TO DO.\n",
    "\n",
    "## Oblique Random Forest (ORF)\n",
    "TO DO.\n",
    "[\"On Oblique Random Forests\"](http://people.csail.mit.edu/menze/papers/menze_11_oblique.pdf)\n",
    "\n",
    "## Quantile Random Forest (QRF)\n",
    "TO DO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Bag (OOB) Estimates\n",
    "\n",
    "In random forests, there is no need for cross-validation or a separate test set to get an unbiased estimate of the test set error. It is estimated internally, during the run, as follows:\n",
    "\n",
    "- Each tree is constructed using a different bootstrap sample from the original data. About one-third of the cases are left out of the bootstrap sample and not used in the construction of the kth tree.\n",
    "- Put each case left out in the construction of the kth tree down the kth tree to get a classification. In this way, a test set classification is obtained for each case in about one-third of the trees. \n",
    "- At the end of the run, take j to be the class that got most of the votes every time case n was oob. The proportion of times that j is not equal to the true class of n averaged over all cases is the oob error estimate. This has proven to be unbiased in many tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Importance\n",
    "\n",
    "In every tree grown in the forest, put down the OOB cases and count the number of votes cast for the correct class. Now randomly permute the values of variable m in the oob cases and put these cases down the tree.  Subtract the number of votes for the correct class in the variable-$m$-permuted OOB data from the number of votes for the correct class in the untouched OOB data. The average of this number over all trees in the forest is the raw importance score for variable $m$.\n",
    "\n",
    "If the values of this score from tree to tree are independent, then the standard error can be computed by a standard computation. The correlations of these scores between trees have been computed for a number of data sets and proved to be quite low, therefore we compute standard errors in the classical way, divide the raw score by its standard error to get a $z$-score, ands assign a significance level to the $z$-score assuming normality.\n",
    "\n",
    "If the number of variables is very large, forests can be run once with all the variables, then run again using only the most important variables from the first run.\n",
    "\n",
    "For each case, consider all the trees for which it is oob. Subtract the percentage of votes for the correct class in the variable-$m$-permuted OOB data from the percentage of votes for the correct class in the untouched OOB data. This is the local importance score for variable m for this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Leo Brieman famously claimed that \"Random Forests do not overfit.\"  This is perhaps not exactly the case, however they are certainly more robust to overfitting than a Gradient Boosting Machine (GBM).  \n",
    "\n",
    "TO DO.\n",
    "\n",
    "\n",
    "## Missing Data\n",
    "\n",
    "Missing values do not neccessarily have to be imputed in a Random Forest implemenation, although some software packages will require it.  \n",
    "\n",
    "- TO DO: Brieman's approach\n",
    "- TO DO: H2O's approach, etc.\n",
    "\n",
    "## Practical Uses\n",
    "\n",
    "Here is a short article called, [The Unreasonable Effectiveness of Random Forests](https://medium.com/rants-on-machine-learning/the-unreasonable-effectiveness-of-random-forests-f33c3ce28883#.r734znc9f), by Ahmed El Deeb, about the utility of Random Forests.  It summarizes some of the algorithm's pros and cons nicely.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Software in R \n",
    "\n",
    "The oldest and most well known implementation of the Random Forest algorithm in R is the [randomForest](https://cran.r-project.org/web/packages/randomForest/index.html) package.  There are also a number of packages that implement variants of the algorithm, and in the past few years, there have been several \"big data\" focused implementations contributed to the R ecosystem as well.\n",
    "\n",
    "Here is a non-comprehensive list:\n",
    "\n",
    "- [randomForest::randomForest](http://www.rdocumentation.org/packages/randomForest/functions/randomForest)\n",
    "- [h2o::h2o.randomForest](http://www.rdocumentation.org/packages/h2o/functions/h2o.randomForest)\n",
    "- [DistributedR::hpdRF_parallelForest](https://github.com/vertica/DistributedR/blob/master/algorithms/HPdclassifier/R/hpdRF_parallelForest.R)\n",
    "- [party::cForest](http://www.rdocumentation.org/packages/party/functions/cforest): A random forest variant for response variables measured at arbitrary scales based on conditional inference trees.\n",
    "- [randomForestSRC](https://cran.r-project.org/web/packages/randomForestSRC/index.html) implements a unified treatment of Breiman's random forests for survival, regression and classification problems.\n",
    "- [quantregForest](https://cran.r-project.org/web/packages/quantregForest/index.html) can regress quantiles of a numeric response on exploratory variables via a random forest approach.\n",
    "- [ranger](https://cran.r-project.org/web/packages/ranger/index.html)\n",
    "- [Rborist](https://cran.r-project.org/web/packages/Rborist/index.html)\n",
    "- The [caret](https://topepo.github.io/caret/index.html) package wraps a number of different Random Forest packages in R ([full list here](https://topepo.github.io/caret/Random_Forest.html)):\n",
    "  - Conditional Inference Random Forest (`party::cForest`)\n",
    "  - Oblique Random Forest (`obliqueRF`)\n",
    "  - Parallel Random Forest (`randomForest` + `foreach`)\n",
    "  - Random Ferns (`rFerns`)\n",
    "  - Random Forest (`randomForest`)\n",
    "  - Random Forest (`ranger`)\n",
    "  - Quantile Random Forest (`quantregForest`)\n",
    "  - Random Forest by Randomization (`extraTrees`)\n",
    "  - Random Forest Rule-Based Model (`inTrees`)\n",
    "  - Random Forest with Additional Feature Selection (`Boruta`)\n",
    "  - Regularized Random Forest (`RRF`)\n",
    "  - Rotation Forest (`rotationForest`)\n",
    "  - Weighted Subspace Random Forest (`wsrf`)\n",
    "- The [mlr](https://github.com/mlr-org/mlr) package wraps a number of different Random Forest packages in R:\n",
    "  - Conditional Inference Random Forest (`party::cForest`)\n",
    "  - Rotation Forest (`rotationForest`)\n",
    "  - Parallel Forest (`ParallelForest`)\n",
    "  - Survival Forest (`randomForestSRC`)\n",
    "  - Random Ferns (`rFerns`)\n",
    "  - Random Forest (`randomForest`)\n",
    "  - Random Forest (`ranger`)\n",
    "  - Synthetic Random Forest (`randomForestSRC`)\n",
    "  - Random Uniform Forest (`randomUniformForest`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## randomForest\n",
    "\n",
    "Authors: Fortran original by [Leo Breiman](http://www.stat.berkeley.edu/~breiman/) and [Adele Cutler](http://www.math.usu.edu/~adele/), R port by [Andy Liaw](https://www.linkedin.com/in/andy-liaw-1399347) and Matthew Wiener.\n",
    "\n",
    "Backend: Fortran\n",
    "\n",
    "Features:\n",
    "- This package wraps the original Fortran code by Leo Breiman and Adele Culter and is probably the most widely known/used implemenation in R.\n",
    "- Single-threaded.\n",
    "- Although it's single-threaded, smaller forests can be trained in parallel by writing custom [foreach](https://cran.r-project.org/web/packages/foreach/index.html) or [parallel](http://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf) code, then combined into a bigger forest using the `randomForest::combine` function.\n",
    "- Row weights unimplemented (been on the wishlist for as long as I can remember).\n",
    "- Uses CART trees split by Gini Impurity.\n",
    "- Categorical predictors are allowed to have up to 53 categories.\n",
    "- Multinomial response can have no more than 32 categories.\n",
    "- Supports R formula interface (but I've read some reports that claim it's slower to use the formula interface)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# randomForest example\n",
    "#install.packages(\"randomForest\")\n",
    "#install.packages(\"cvAUC\")\n",
    "library(randomForest)\n",
    "library(cvAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>5000</li>\n",
       "\t<li>29</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5000\n",
       "\\item 29\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5000\n",
       "2. 29\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5000   29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>5000</li>\n",
       "\t<li>29</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5000\n",
       "\\item 29\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5000\n",
       "2. 29\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5000   29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'response'</li>\n",
       "\t<li>'x1'</li>\n",
       "\t<li>'x2'</li>\n",
       "\t<li>'x3'</li>\n",
       "\t<li>'x4'</li>\n",
       "\t<li>'x5'</li>\n",
       "\t<li>'x6'</li>\n",
       "\t<li>'x7'</li>\n",
       "\t<li>'x8'</li>\n",
       "\t<li>'x9'</li>\n",
       "\t<li>'x10'</li>\n",
       "\t<li>'x11'</li>\n",
       "\t<li>'x12'</li>\n",
       "\t<li>'x13'</li>\n",
       "\t<li>'x14'</li>\n",
       "\t<li>'x15'</li>\n",
       "\t<li>'x16'</li>\n",
       "\t<li>'x17'</li>\n",
       "\t<li>'x18'</li>\n",
       "\t<li>'x19'</li>\n",
       "\t<li>'x20'</li>\n",
       "\t<li>'x21'</li>\n",
       "\t<li>'x22'</li>\n",
       "\t<li>'x23'</li>\n",
       "\t<li>'x24'</li>\n",
       "\t<li>'x25'</li>\n",
       "\t<li>'x26'</li>\n",
       "\t<li>'x27'</li>\n",
       "\t<li>'x28'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'response'\n",
       "\\item 'x1'\n",
       "\\item 'x2'\n",
       "\\item 'x3'\n",
       "\\item 'x4'\n",
       "\\item 'x5'\n",
       "\\item 'x6'\n",
       "\\item 'x7'\n",
       "\\item 'x8'\n",
       "\\item 'x9'\n",
       "\\item 'x10'\n",
       "\\item 'x11'\n",
       "\\item 'x12'\n",
       "\\item 'x13'\n",
       "\\item 'x14'\n",
       "\\item 'x15'\n",
       "\\item 'x16'\n",
       "\\item 'x17'\n",
       "\\item 'x18'\n",
       "\\item 'x19'\n",
       "\\item 'x20'\n",
       "\\item 'x21'\n",
       "\\item 'x22'\n",
       "\\item 'x23'\n",
       "\\item 'x24'\n",
       "\\item 'x25'\n",
       "\\item 'x26'\n",
       "\\item 'x27'\n",
       "\\item 'x28'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'response'\n",
       "2. 'x1'\n",
       "3. 'x2'\n",
       "4. 'x3'\n",
       "5. 'x4'\n",
       "6. 'x5'\n",
       "7. 'x6'\n",
       "8. 'x7'\n",
       "9. 'x8'\n",
       "10. 'x9'\n",
       "11. 'x10'\n",
       "12. 'x11'\n",
       "13. 'x12'\n",
       "14. 'x13'\n",
       "15. 'x14'\n",
       "16. 'x15'\n",
       "17. 'x16'\n",
       "18. 'x17'\n",
       "19. 'x18'\n",
       "20. 'x19'\n",
       "21. 'x20'\n",
       "22. 'x21'\n",
       "23. 'x22'\n",
       "24. 'x23'\n",
       "25. 'x24'\n",
       "26. 'x25'\n",
       "27. 'x26'\n",
       "28. 'x27'\n",
       "29. 'x28'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"response\" \"x1\"       \"x2\"       \"x3\"       \"x4\"       \"x5\"      \n",
       " [7] \"x6\"       \"x7\"       \"x8\"       \"x9\"       \"x10\"      \"x11\"     \n",
       "[13] \"x12\"      \"x13\"      \"x14\"      \"x15\"      \"x16\"      \"x17\"     \n",
       "[19] \"x18\"      \"x19\"      \"x20\"      \"x21\"      \"x22\"      \"x23\"     \n",
       "[25] \"x24\"      \"x25\"      \"x26\"      \"x27\"      \"x28\"     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load binary-response dataset\n",
    "train <- read.csv(\"data/higgs_train_5k.csv\")\n",
    "test <- read.csv(\"data/higgs_test_5k.csv\")\n",
    "\n",
    "# Dimensions\n",
    "dim(train)\n",
    "dim(test)\n",
    "\n",
    "# Columns\n",
    "names(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identity the response column\n",
    "ycol <- \"response\"\n",
    "\n",
    "# Identify the predictor columns\n",
    "xcols <- setdiff(names(train), ycol)\n",
    "\n",
    "# Convert response to factor (required by randomForest)\n",
    "train[,ycol] <- as.factor(train[,ycol])\n",
    "test[,ycol] <- as.factor(test[,ycol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  1.253   0.006   1.258 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train a default RF model with 500 trees\n",
    "set.seed(1)  # For reproducibility\n",
    "system.time(fit <- randomForest(x = train[,xcols], \n",
    "                                y = train[,ycol],\n",
    "                                xtest = test[,xcols],\n",
    "                                ntree = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.763690368457674"
      ],
      "text/latex": [
       "0.763690368457674"
      ],
      "text/markdown": [
       "0.763690368457674"
      ],
      "text/plain": [
       "[1] 0.7636904"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions on test dataset\n",
    "preds <- fit$test$votes[, 2]\n",
    "\n",
    "# Compute AUC on the test set\n",
    "cvAUC::AUC(predictions = preds, labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## caret method \"parRF\"\n",
    "\n",
    "Authors: TO DO\n",
    "\n",
    "Backend: TO DO\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(doParallel)\n",
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train a \"parRF\" model using caret\n",
    "registerDoParallel(cores = 8)\n",
    "\n",
    "fit <- caret::train(x = train[,xcols], \n",
    "                    y = train[,ycol], \n",
    "                    method = \"parRF\",\n",
    "                    preProcess = NULL,\n",
    "                    weights = NULL,\n",
    "                    metric = \"Accuracy\",\n",
    "                    maximize = TRUE,\n",
    "                    trControl = trainControl(), \n",
    "                    tuneGrid = NULL,\n",
    "                    tuneLength = 3)\n",
    "\n",
    "# TO DO: Evaluate performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h2o\n",
    "\n",
    "Authors: [Jan Vitek](http://www.cs.purdue.edu/homes/jv/), [Arno Candel](https://www.linkedin.com/in/candel), H2O.ai contributors\n",
    "\n",
    "Backend: Java\n",
    "\n",
    "Features:\n",
    "\n",
    "- Multi-threaded.\n",
    "- Data-distributed, which means the entire dataset does not need to fit into memory on a single node.\n",
    "- Uses histogram approximations of continuous variables for speedup.\n",
    "- Uses squared error to determine optimal splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2o.shutdown(prompt = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "H2O is not running yet, starting it now...\n",
      "\n",
      "Note:  In case of errors look at the following log files:\n",
      "    /var/folders/2j/jg4sl53d5q53tc2_nzm9fz5h0000gn/T//RtmpZIIhCg/h2o_me_started_from_r.out\n",
      "    /var/folders/2j/jg4sl53d5q53tc2_nzm9fz5h0000gn/T//RtmpZIIhCg/h2o_me_started_from_r.err\n",
      "\n",
      "\n",
      "Starting H2O JVM and connecting: . Connection successful!\n",
      "\n",
      "R is connected to the H2O cluster: \n",
      "    H2O cluster uptime:         1 seconds 102 milliseconds \n",
      "    H2O cluster version:        3.8.2.6 \n",
      "    H2O cluster name:           H2O_started_from_R_me_msf556 \n",
      "    H2O cluster total nodes:    1 \n",
      "    H2O cluster total memory:   3.56 GB \n",
      "    H2O cluster total cores:    8 \n",
      "    H2O cluster allowed cores:  8 \n",
      "    H2O cluster healthy:        TRUE \n",
      "    H2O Connection ip:          localhost \n",
      "    H2O Connection port:        54321 \n",
      "    H2O Connection proxy:       NA \n",
      "    R Version:                  R version 3.3.0 (2016-05-03) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#install.packages(\"h2o\")\n",
    "library(h2o)\n",
    "h2o.init(nthreads = -1)  #Start a local H2O cluster using nthreads = num available cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>5000</li>\n",
       "\t<li>29</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5000\n",
       "\\item 29\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5000\n",
       "2. 29\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5000   29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>5000</li>\n",
       "\t<li>29</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5000\n",
       "\\item 29\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5000\n",
       "2. 29\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5000   29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'response'</li>\n",
       "\t<li>'x1'</li>\n",
       "\t<li>'x2'</li>\n",
       "\t<li>'x3'</li>\n",
       "\t<li>'x4'</li>\n",
       "\t<li>'x5'</li>\n",
       "\t<li>'x6'</li>\n",
       "\t<li>'x7'</li>\n",
       "\t<li>'x8'</li>\n",
       "\t<li>'x9'</li>\n",
       "\t<li>'x10'</li>\n",
       "\t<li>'x11'</li>\n",
       "\t<li>'x12'</li>\n",
       "\t<li>'x13'</li>\n",
       "\t<li>'x14'</li>\n",
       "\t<li>'x15'</li>\n",
       "\t<li>'x16'</li>\n",
       "\t<li>'x17'</li>\n",
       "\t<li>'x18'</li>\n",
       "\t<li>'x19'</li>\n",
       "\t<li>'x20'</li>\n",
       "\t<li>'x21'</li>\n",
       "\t<li>'x22'</li>\n",
       "\t<li>'x23'</li>\n",
       "\t<li>'x24'</li>\n",
       "\t<li>'x25'</li>\n",
       "\t<li>'x26'</li>\n",
       "\t<li>'x27'</li>\n",
       "\t<li>'x28'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'response'\n",
       "\\item 'x1'\n",
       "\\item 'x2'\n",
       "\\item 'x3'\n",
       "\\item 'x4'\n",
       "\\item 'x5'\n",
       "\\item 'x6'\n",
       "\\item 'x7'\n",
       "\\item 'x8'\n",
       "\\item 'x9'\n",
       "\\item 'x10'\n",
       "\\item 'x11'\n",
       "\\item 'x12'\n",
       "\\item 'x13'\n",
       "\\item 'x14'\n",
       "\\item 'x15'\n",
       "\\item 'x16'\n",
       "\\item 'x17'\n",
       "\\item 'x18'\n",
       "\\item 'x19'\n",
       "\\item 'x20'\n",
       "\\item 'x21'\n",
       "\\item 'x22'\n",
       "\\item 'x23'\n",
       "\\item 'x24'\n",
       "\\item 'x25'\n",
       "\\item 'x26'\n",
       "\\item 'x27'\n",
       "\\item 'x28'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'response'\n",
       "2. 'x1'\n",
       "3. 'x2'\n",
       "4. 'x3'\n",
       "5. 'x4'\n",
       "6. 'x5'\n",
       "7. 'x6'\n",
       "8. 'x7'\n",
       "9. 'x8'\n",
       "10. 'x9'\n",
       "11. 'x10'\n",
       "12. 'x11'\n",
       "13. 'x12'\n",
       "14. 'x13'\n",
       "15. 'x14'\n",
       "16. 'x15'\n",
       "17. 'x16'\n",
       "18. 'x17'\n",
       "19. 'x18'\n",
       "20. 'x19'\n",
       "21. 'x20'\n",
       "22. 'x21'\n",
       "23. 'x22'\n",
       "24. 'x23'\n",
       "25. 'x24'\n",
       "26. 'x25'\n",
       "27. 'x26'\n",
       "28. 'x27'\n",
       "29. 'x28'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"response\" \"x1\"       \"x2\"       \"x3\"       \"x4\"       \"x5\"      \n",
       " [7] \"x6\"       \"x7\"       \"x8\"       \"x9\"       \"x10\"      \"x11\"     \n",
       "[13] \"x12\"      \"x13\"      \"x14\"      \"x15\"      \"x16\"      \"x17\"     \n",
       "[19] \"x18\"      \"x19\"      \"x20\"      \"x21\"      \"x22\"      \"x23\"     \n",
       "[25] \"x24\"      \"x25\"      \"x26\"      \"x27\"      \"x28\"     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load binary-response dataset\n",
    "train <- h2o.importFile(\"./data/higgs_train_5k.csv\")\n",
    "test <- h2o.importFile(\"./data/higgs_test_5k.csv\")\n",
    "\n",
    "# Dimensions\n",
    "dim(train)\n",
    "dim(test)\n",
    "\n",
    "# Columns\n",
    "names(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identity the response column\n",
    "ycol <- \"response\"\n",
    "\n",
    "# Identify the predictor columns\n",
    "xcols <- setdiff(names(train), ycol)\n",
    "\n",
    "# Convert response to factor (required by randomForest)\n",
    "train[,ycol] <- as.factor(train[,ycol])\n",
    "test[,ycol] <- as.factor(test[,ycol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  |                                                                            \r",
      "  |                                                                      |   0%\r",
      "  |                                                                            \r",
      "  |=                                                                     |   1%\r",
      "  |                                                                            \r",
      "  |====================                                                  |  29%\r",
      "  |                                                                            \r",
      "  |===================================                                   |  50%\r",
      "  |                                                                            \r",
      "  |==============================================                        |  66%\r",
      "  |                                                                            \r",
      "  |=========================================================             |  82%\r",
      "  |                                                                            \r",
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.184   0.007   5.300 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train a default RF model with 100 trees\n",
    "\n",
    "system.time(fit <- h2o.randomForest(x = xcols,\n",
    "                                    y = ycol,\n",
    "                                    training_frame = train,\n",
    "                                    seed = 1, #for reproducibility\n",
    "                                    ntrees = 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.771561631494061"
      ],
      "text/latex": [
       "0.771561631494061"
      ],
      "text/markdown": [
       "0.771561631494061"
      ],
      "text/plain": [
       "[1] 0.7715616"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute AUC on test dataset\n",
    "# H2O computes many model performance metrics automatically, including AUC\n",
    "\n",
    "rf_perf1 <- h2o.performance(model = fit, \n",
    "                            newdata = test)\n",
    "h2o.auc(rf_perf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ranger\n",
    "\n",
    "Authors: TO DO\n",
    "\n",
    "Backend: C++\n",
    "\n",
    "Features:\n",
    "\n",
    "- Multi-threaded.\n",
    "- Direct support for [GWAS](https://en.wikipedia.org/wiki/Genome-wide_association_study) data.\n",
    "- Excellent speed and support for high-dimensional or wide data.\n",
    "- Not as fast for \"tall & skinny\" data (many rows, few columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "[1] [P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006.](http://link.springer.com/article/10.1007%2Fs10994-006-6226-1)\n",
    "\n",
    "[2] [http://www.stat.berkeley.edu/~breiman/randomforest2001.pdf](http://www.stat.berkeley.edu/~breiman/randomforest2001.pdf)\n",
    "\n",
    "[3] [http://www.cs.uvm.edu/~icdm/algorithms/10Algorithms-08.pdf](http://www.cs.uvm.edu/~icdm/algorithms/10Algorithms-08.pdf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
